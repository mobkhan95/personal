{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear Problems in Finance (MATHGR5400), Columbia University, Spring 2019\n",
    "# Homework III\n",
    "\n",
    "### Due Date: 04:00 PM Friday, April 5, 2019\n",
    "You should turn in the notebook at Columbia CourseWorks website\n",
    "\n",
    "Please comment your code properly.\n",
    "\n",
    "Before you turn in the notebook, press the \"Run all cells\" button in the toolbar, and make sure all the calculation results and graphs are produced correctly in a reasonable time frame, and then save the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertain Mortality Model vs American Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Re-insurance Deals**\n",
    "\n",
    "In this assignment, we study the *Uncertain Mortality Model* for the pricing of reinsurance deals. For the sake of simplicity, in this assignment we only consider one type of default: the risk of death.\n",
    "\n",
    "We consider the following reinsurance product:\n",
    "\n",
    "- At maturity, if the insurance subscriber is alive, the issuer delivers a put on the underlying $X$\n",
    "\n",
    "$$\n",
    "u^\\textrm{mat}( x) = (K_\\textrm{mat} - x)_+.\n",
    "$$\n",
    "\n",
    "- At the time of death, if it is before the maturity, the issuer delivers an exit payoff, typically another put on the underlying $X$.\n",
    "\n",
    "$$\n",
    "u^D(t, x) = (K_D - x)_+.\n",
    "$$\n",
    "\n",
    "- The subscriber pays a constant fee $Î±\\Delta t$ at every time step until death or the maturity or the product\n",
    "\n",
    "- The insurance sells a large number of these contracts to subscribers. We assume that the times of death of the subscribers $\\tau^D$ are independent, and identically distributed, and also independent of the underlying's stock price.\n",
    "\n",
    "- We assume that the underlying's risk neutral price dynamics is the Black-Scholes model with zero interest rate/repo/dividend yield\n",
    "\n",
    "$$\n",
    "dX_t = \\sigma X_t d W_t.\n",
    "$$\n",
    "\n",
    "** The Insurers' Approach and Risk-Neutral Pricing**\n",
    "\n",
    "This contract shows two types of risk: the times of death of the subscribers and the changes in the price of the underlying. \n",
    "\n",
    "In this case, the issuer can apply the insurer's approach to the risk of death times, i.e., the law of large numbers. The more people buy the contract, the less risk.\n",
    "\n",
    "Choosing a risk-neutral measure under which the death times $\\tau^D$ have the same distribution as under the historical probability measure is equivalent to applying the arbitrage-pricing approach to the financial risk insurer's rule on the risk of death. The price of the contract is then\n",
    "\n",
    "$$\n",
    "u(t, x) = \\mathbb{E}^\\mathbb{Q}_{t, x} \\left[u^\\textrm{mat}(X_T) \\mathbb{1}_{\\tau^D \\geq T} -\\int_t^T\\alpha\\mathbb{1}_{\\tau^D>s}ds+ u^D(\\tau^D, X_{\\tau^D}) \\mathbb{1}_{\\tau^D < T} \\right].\n",
    "$$\n",
    "\n",
    "** Deterministic Death Rate **\n",
    "\n",
    "If the death intensity is a deterministic function $\\lambda_t^D$ (i.e. $\\tau^D$ has an exponential distribution with time-dependent intensity $\\lambda_t^D$), then we have seen that $u$ is the solution to the linear PDE\n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{array}{l}\n",
    "\\partial_t u + \\frac{1}{2} \\sigma^2 x^2 \\partial_x^2 u -\\alpha + \\lambda_t^D \\cdot (u^D - u) = 0,\\\\\n",
    "u(T, \\cdot) \\equiv u^\\textrm{mat}.\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "** Uncertain Mortality Model **\n",
    "\n",
    "If the death rate is uncertain, we assume that it is adapted (i.e., it does not look into the future) and belongs to a moving corridor\n",
    "$\\left[\\underline{\\lambda}_t, \\overline{\\lambda}_t\\right]$. The most conservative way to price the contract is to compute the (financially) worst death rate process $\\lambda_t^D$ as being chosen so as to maximize the value of the contract. The resulting HJB equation is\n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{array}{l}\n",
    "\\partial_t u + \\frac{1}{2} \\sigma^2 x^2 \\partial^2_x u -\\alpha + \\Lambda^D(t, u^D - u) \\cdot (u^D - u) = 0,\\\\\n",
    "u(T, \\cdot) \\equiv u^\\textrm{mat},\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "where the function $\\Lambda^D$ is defined by\n",
    "$$\n",
    "\\Lambda^D (t, y) = \\left\\{\\begin{array}{l}\n",
    "    \\overline{\\lambda}^D_t \\quad \\textrm{if} \\ y \\geq 0, \\\\\n",
    "    \\underline{\\lambda}^D_t \\quad \\textrm{otherwise.}\n",
    "\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link with $1$-BSDE and Numerical Schemes\n",
    "\n",
    "From the Pardoux-Peng theorem, we know that the solution $u(0, x)$ can be represented as the solution $Y_0^x$ to the $1$-BSDE\n",
    "\n",
    "$$\n",
    "dY_t = -f(t, X_t, Y_t, Z_t) \\, dt + Z_t \\, dW_t,\n",
    "$$\n",
    "\n",
    "with the terminal condition $Y_T = u^\\textrm{mat} (X_T)$, where $X_0 = x$ and\n",
    "\n",
    "$$\n",
    "f(t, x, y, z) = -\\alpha + \\Lambda^D(t, u^D(t, x) - y) \\cdot (u^D(t, x) - y).\n",
    "$$\n",
    "\n",
    "\n",
    "## BSDE Discretization\n",
    "\n",
    "### Explicit Euler Schemes\n",
    "\n",
    "\\begin{align*}\n",
    "Y_{t_n} =& \\ u^{\\text{mat}}\\left(X_{t_n}\\right)\\\\\n",
    "Y_{t_{i - 1}} =& \\ \\mathbb{E}^\\mathbb{Q}_{i - 1} [ Y_{t_i} ] -\\alpha\\Delta t_i + \\Lambda^D \\left(t_{i - 1}, u^D(t_{i - 1} , X_{t_{i - 1}}) - \\mathbb{E}^\\mathbb{Q}_{i - 1} [ Y_{t_i} ]\\right) \\cdot \\left( u^D(t_{i - 1}, X_{t_{i - 1}}) - \\mathbb{E}^\\mathbb{Q}_{i - 1} [ Y_{t_i} ] \\right) \\Delta t_i\\\\\n",
    "=& -\\alpha\\Delta t_i + \\left( \\mathbb{E}^\\mathbb{Q}_{i - 1} [ Y_{t_i} ] \\left( 1 - \\overline{\\lambda}^D \\Delta t_i \\right) +\n",
    "u^D(t_{i - 1}, X_{t_{i - 1}}) \\overline{\\lambda}^D \\Delta t_i \\right) \\mathbb{1}_{u^D\\left(t_{i - 1}, X_{t_{i - 1}}\\right) \\geq \\mathbb{E}_{i-1}[Y_{t_i}]}\\\\\n",
    "& + \\left( \\mathbb{E}^\\mathbb{Q}_{i - 1} [ Y_{t_i} ] \\left( 1 - \\underline{\\lambda}^D \\Delta t_i \\right) +\n",
    "u^D(t_{i - 1}, X_{t_{i - 1}}) \\underline{\\lambda}^D \\Delta t_i \\right) \\mathbb{1}_{u^D\\left(t_{i - 1}, X_{t_{i - 1}}\\right) < \\mathbb{E}_{i-1}[Y_{t_i}]}.\n",
    "\\end{align*}\n",
    "\n",
    "### Implicit Euler Scheme\n",
    "\n",
    "\\begin{align*}\n",
    "Y_{t_n} =& \\ u^{\\text{mat}}\\left(X_{t_n}\\right)\\\\\n",
    "Y_{t_{i - 1}} =& \\ \\mathbb{E}^\\mathbb{Q}_{i - 1} [Y_{t_i}] -\\alpha\\Delta t_i+ \\Lambda^D \\left(t_{i - 1}, u^D(t_{i - 1}, X_{t_{i - 1}}) - Y_{t_{i - 1}}\\right) \\cdot \\left( u^D(t_{i - 1}, X_{t_{i - 1}}) - Y_{t_{i - 1}} \\right) \\Delta t_i.\n",
    "\\end{align*}\n",
    "\n",
    "The implicit scheme involves $Y_{t_{i - 1}}$ on both sides of the equation, which generally requires a root-finding routine to find $Y_{t_{i - 1}}$. However in this specific case, it can be shown that \n",
    "\n",
    "\\begin{equation}u^D(t_{i-1}, X_{t_{i-1}}) \\geq Y_{t_{i-1}}\\quad\\text{if and only if}\\quad u^D(t_{i-1}, X_{t_{i-1}}) \\geq \\mathbb{E}^{\\mathbb{Q}}_{i-1}\\left[Y_{t_i}\\right]-\\alpha\\Delta t_i.\\end{equation}\n",
    "\n",
    "Thus\n",
    "\n",
    "\\begin{split}\n",
    "Y_{t_{i - 1}} =& \\frac{1}{1 + \\overline{\\lambda}^D \\Delta t_i} \\left( \\mathbb{E}^\\mathbb{Q}_{i - 1} [ Y_{t_i} ] - \\alpha\\Delta t_i +\n",
    "u^D(t_{i - 1}, X_{t_{i - 1}}) \\overline{\\lambda}^D \\Delta t_i \\right) \\mathbb{1}_{u^D\\left(t_{i - 1}, X_{t_{i - 1}}\\right) \\geq \\mathbb{E}_{i-1}[Y_{t_i}]-\\alpha\\Delta t_i}\\\\\n",
    "& + \\frac{1}{1 + \\underline{\\lambda}^D \\Delta t_i} \\left( \\mathbb{E}^\\mathbb{Q}_{i - 1} [ Y_{t_i} ] -\\alpha\\Delta t_i +\n",
    "u^D(t_{i - 1}, X_{t_{i - 1}}) \\underline{\\lambda}^D \\Delta t_i \\right) \\mathbb{1}_{u^D(t_{i - 1}, X_{t_{i - 1}}) < \\mathbb{E}_{i-1}[Y_{t_i}]-\\alpha\\Delta t_i}.\n",
    "\\end{split}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackscholes_mc(S=100, vol=0.2, r=0, q=0, ts=np.linspace(0, 1, 13), npaths=10):\n",
    "    \"\"\"Generate Monte-Carlo paths in Black-Scholes model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    S: scalar\n",
    "        The spot price of the underlying security.\n",
    "    vol: scalar\n",
    "        The implied Black-Scholes volatility.\n",
    "    r: scalar\n",
    "        The annualized risk-free interest rate, continuously compounded.\n",
    "    q: scalar\n",
    "        The annualized continuous dividend yield.\n",
    "    ts: array_like\n",
    "        The time steps of the simualtion\n",
    "    npaths: int\n",
    "        the number of paths to simulate\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    paths: ndarray\n",
    "        The Monte-Carlo paths.\n",
    "    \"\"\"\n",
    "    nsteps = len(ts) - 1\n",
    "    ts = np.asfarray(ts)[:, np.newaxis]\n",
    "    W = np.cumsum(np.vstack((np.zeros((1, npaths), dtype=np.float),\n",
    "                             np.random.randn(nsteps, npaths) * np.sqrt(np.diff(ts, axis=0)))),\n",
    "                  axis=0)\n",
    "    paths = np.exp(-0.5*vol**2*ts + vol*W)*S*np.exp((r-q)*ts)\n",
    "    return paths\n",
    "\n",
    "def blackscholes_price(K, T, S, vol, r=0, q=0, callput='call'):\n",
    "    \"\"\"Compute the call/put option price in the Black-Scholes model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    K: scalar or array_like\n",
    "        The strike of the option.\n",
    "    T: scalar or array_like\n",
    "        The maturity of the option, expressed in years (e.g. 0.25 for 3-month and 2 for 2 years)\n",
    "    S: scalar or array_like\n",
    "        The current price of the underlying asset.\n",
    "    vol: scalar or array_like\n",
    "        The implied Black-Scholes volatility.\n",
    "    r: scalar or array_like\n",
    "        The annualized risk-free interest rate, continuously compounded.\n",
    "    q: scalar or array_like\n",
    "        The annualized continuous dividend yield.\n",
    "    callput: str\n",
    "        Must be either 'call' or 'put'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    price: scalar or array_like\n",
    "        The price of the option.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> blackscholes_price(95, 0.25, 100, 0.2, r=0.05, callput='put')\n",
    "    1.5342604771222823\n",
    "    \"\"\"\n",
    "    F = S*np.exp((r-q)*T)\n",
    "    v = np.sqrt(vol**2*T)\n",
    "    d1 = np.log(F/K)/v + 0.5*v\n",
    "    d2 = d1 - v\n",
    "    try:\n",
    "        opttype = {'call':1, 'put':-1}[callput.lower()]\n",
    "    except:\n",
    "        raise ValueError('The value of callput must be either \"call\" or \"put\".')\n",
    "    price = opttype*(F*norm.cdf(opttype*d1)-K*norm.cdf(opttype*d2))*np.exp(-r*T)\n",
    "    return price\n",
    "\n",
    "\n",
    "def pwlinear_basis(xknots):\n",
    "    \"\"\"Basis that represent a piecewise linear function with given knots\"\"\"\n",
    "    fs = [lambda x: np.ones_like(x, dtype=np.float), lambda x: x-xknots[0]]\n",
    "    fs.extend([lambda x, a=xknots[i]: np.maximum(x-a, 0) for i in range(len(xknots))])\n",
    "    return fs\n",
    "\n",
    "\n",
    "def pwlinear_fit(xdata, ydata, xknots):\n",
    "    \"\"\"Fit a piecewise linear function with xknots to xdata and ydata\"\"\"\n",
    "    fs = pwlinear_basis(xknots)\n",
    "    A = np.vstack([f(xdata) for f in fs]).T\n",
    "    ps = np.linalg.lstsq(A, ydata, rcond=None)[0]\n",
    "    return ps, fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note.</b> To be more specific about the payouts of the product, we make the following assumptions:\n",
    "\n",
    "- We assume that all transactions occur at the end of the month, i.e. the insurance subsriber is expected to pay a fee of $\\alpha/12$ at the end of each month; if the subscriber dies in the middle of the month, the death payment will be made at the end of that month. \n",
    "\n",
    "- If the death occurs at the maturity, we assume that the death comes first and the death payment $u^D$ will be made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment III\n",
    "\n",
    "<b style=\"color:darkorange\">Question 1</b> (Deterministic Mortality Rate Model)\n",
    "\n",
    "We assume that the underlying's risk neutral price dynamics is the Black-Scholes model with zero interest rate/repo/dividend yield\n",
    "\n",
    "$$dX_t = \\sigma X_t d W_t,\\quad X_0=100,\\quad\\sigma=0.3$$\n",
    "\n",
    "We shall price the reinsurance deal using two Monte Carlo methods explained below.\n",
    "\n",
    "<b>(a).</b> (Direct simulation of death times) Implement a Monte Carlo simulation by directly simulating death time $\\tau^D$ for each path to estimate the quantity\n",
    "\n",
    "$$u(t, x) = \\mathbb{E}^\\mathbb{Q}_{t, x} \\left[u^\\textrm{mat}(X_T) \\mathbb{1}_{\\tau^D \\geq T} - \\int_t^T\\alpha \\mathbb{1}_{\\tau^D> s}ds\n",
    "+ u^D(\\tau^D, X_{\\tau^D}) \\mathbb{1}_{\\tau^D < T} \\right],$$\n",
    "\n",
    "when $T=10$, $K_{\\text{mat}}=90$, $K_D=100$, $\\alpha=3$, and $\\tau^D$ has an exponential distribution of constant intensity $\\lambda^D=0.025$. Use monthly time steps.\n",
    "\n",
    "<b>(b).</b> (Averaing over death events) Using the Feynman-Kac formula, derive a stochastic representation of the linear PDE \n",
    "\n",
    "$$\\left\\{\\begin{array}{l}\\partial_t u + \\frac{1}{2}\\sigma^2 x^2 \\partial_x^2 u - \\alpha + \\lambda^D \\cdot (u^D - u) = 0\\\\\n",
    "        u(T, x) \\equiv u^\\textrm{mat}(x)\\end{array}\\right.$$\n",
    "        \n",
    "that does not involve simulating death times $\\tau^D$. Explain how one can get this stochastic representation from the one given in (a). Implement the corresponding Monte Carlo simulation to estimate $u(0,X_0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that lambda is a reserved keyword in python, so we use lambd instead\n",
    "def exponential_samples(n, lambd):\n",
    "    \"\"\"Generate n samples from exponential distribution with rate lambd\"\"\"\n",
    "    return -np.log(np.random.rand(n))/lambd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def u_mat(x):\n",
    "    return np.maximum(K_mat - x, 0)\n",
    "\n",
    "def u_D(x):\n",
    "    return np.maximum(K_D - x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0201625838269166"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating 100000 market paths\n",
    "S = 100\n",
    "vol = 0.3\n",
    "T = 10\n",
    "ts = np.linspace(0, T, int(np.round(T*12))+1)\n",
    "alpha = 3\n",
    "lambda_d = 0.025\n",
    "K_mat = 90.0\n",
    "K_D = 100.0\n",
    "\n",
    "npaths = 100000\n",
    "paths = blackscholes_mc(S=S, vol=vol, r=0, q=0, ts=ts, npaths=npaths)\n",
    "\n",
    "#generate times of 1st arrival of exponential distribution with parameter lambda_d\n",
    "arriv = exponential_samples(npaths, lambda_d)\n",
    "\n",
    "#alter arrival times so that for arrival time, t, t <= T, t is rounded to the value in the ts array that is greater\n",
    "#than it. This matches the pricing in the LS-like algorithm as it assumes that default does not occur at the current time\n",
    "#For value t >= T, the value is set to be around 1e20, indicating maturity occurs before death\n",
    "a = np.subtract.outer(arriv, np.append(ts,  1e20 + np.max(arriv)))\n",
    "idx = np.ma.argmin(abs(np.ma.MaskedArray(a, a >= 0)) , axis = 1)\n",
    "\n",
    "#calculate payoffs for death occurring at each of the times in the paths matrix, then calculate payoffs for maturity\n",
    "#for the final time of the paths matrix, and then stack them creating a 122 rows by npaths columns matrix\n",
    "payoffs = np.vstack([u_D(paths) + ((-1 * alpha) * ts[:,np.newaxis]) , u_mat(paths[-1]) + ((-1 * alpha) * ts[-1])])\n",
    "\n",
    "#average payoffs over all npaths \n",
    "np.mean(payoffs[idx,np.arange(0,len(paths[1]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using Feymman-Kac, using the form given in the textbook/notes, the $r$ value would be $\\lambda^D$ and the $f$ value would be $\\lambda^Du^D - \\alpha$, and since we are using risk neutral pricing and an interest rate of zero the underlying has no drift and thus the Ito generator of the diffusion $\\mathcal L$ is just (using Black-Scholes framework with constant volatility) $\\mathcal L = \\frac{1}{2}\\sigma^2X_t^2\\partial_x^2u$, and so we have the corresponding values to fit the form of the Feyman-Kac PDE, and so we convert $\\partial_t u + \\frac{1}{2}\\sigma^2 x^2 \\partial_x^2 u - \\alpha + \\lambda^D \\cdot (u^D - u) = 0$ to \n",
    "\\begin{equation}\n",
    "u(t,x) = \\mathbb E_{t,x}^{\\mathbb{Q}}[exp(-\\int_t^T\\lambda^D_sds) u_{mat}(X_T) + \\int_t^T exp(-\\int_t^s\\lambda_r^Ddr) \\cdot (\\lambda^D_su^D(s,X_s) - \\alpha)ds]\n",
    "\\end{equation}\n",
    "matching the given form (after conversion)\n",
    "$$\n",
    "u(t, x) = \\mathbb{E}^\\mathbb{Q}_{t, x} \\left[u^\\textrm{mat}(X_T) \\mathbb{1}_{\\tau^D \\geq T} -\\int_t^T\\alpha\\mathbb{1}_{\\tau^D>s}ds+ u^D(\\tau^D, X_{\\tau^D}) \\mathbb{1}_{\\tau^D < T} \\right].\n",
    "$$\n",
    "This form does not require using the simulation of death times, since it already incorporates the probabilities of death since it conditions on the path of the underlying and using the probability density function of $\\tau^D$.\n",
    "\n",
    "The conversion is done by the following:\n",
    "$\\mathbb E_{t,x}^{\\mathbb{Q}}[u^\\textrm{mat}(X_T) \\mathbb{1}_{\\tau^D \\geq T}]$ is such that $u_mat(X_T)$ is conditionally independent of $\\mathbb{1}_{\\tau^D \\geq T}$ since death times are independent of the path of the underlying. So we calculate $E_{t,x}^{\\mathbb{Q}}[\\mathbb{1}_{\\tau^D \\geq T}]$ using $\\mathbb P^{\\mathbb Q}\\{\\tau^D > T \\; |\\;  \\tau^D > t\\} = exp(-\\int_t^T\\lambda^D_rdr)$ (the probability of no arrivals of a Poisson process of given parameter), resulting in $\\mathbb E_{t,x}^{\\mathbb{Q}}[u^\\textrm{mat}(X_T) \\mathbb{1}_{\\tau^D \\geq T}] = \\mathbb E_{t,x}^{\\mathbb{Q}}[u^\\textrm{mat}(X_T) \\cdot exp(-\\int_t^T\\lambda^D_rdr)]$\n",
    "\n",
    "$\\mathbb{E}^\\mathbb{Q}_{t, x}[-\\int_t^T\\alpha\\mathbb{1}_{\\tau^D>s}ds] = \\alpha \\mathbb{E}^\\mathbb{Q}_{t, x}[-\\int_t^T\\mathbb{1}_{\\tau^D>s}ds]$, and so using Fubini-Tonelli's Theorem we interchange the expectation and integral operators, resulting in $ -\\alpha\\int_t^T\\mathbb{E}^\\mathbb{Q}_{t, x}[\\mathbb{1}_{\\tau^D>s}]ds$, and calculating the expectation using $\\mathbb P^{\\mathbb Q}\\{\\tau^D > s \\; |\\;  \\tau^D > t\\} = exp(-\\int_t^s\\lambda^D_rdr)$, we have $\\mathbb{E}^\\mathbb{Q}_{t, x}[-\\int_t^T\\alpha\\mathbb{1}_{\\tau^D>s}ds] =  -\\alpha\\int_t^Texp(-\\int_t^s\\lambda^D_rdr)ds$\n",
    "\n",
    "$\\mathbb{E}^\\mathbb{Q}_{t, x}[u^D(\\tau^D, X_{\\tau^D}) \\mathbb{1}_{\\tau^D < T}]$ is calculated by using the tower property, conditioning on the entire path of the underlying: $\\mathbb{E}^\\mathbb{Q}_{t, x}[u^D(\\tau^D, X_{\\tau^D}) \\mathbb{1}_{\\tau^D < T}] = \\mathbb{E}^\\mathbb{Q}_{t, x}[\\mathbb{E}^\\mathbb{Q}_{t, x}[u^D(\\tau^D, X_{\\tau^D}) \\mathbb{1}_{\\tau^D < T} \\; | \\{ {X_{u}}\\}_{t \\leq u \\leq T}]]$, and using the PDF of $\\tau^D$, conditioned on the entire path of the underlying and on $\\tau^D > t$, as the PDF of the first arrival time of a Poisson Process $\\lambda^D_s \\cdot exp(-\\int_t^s\\lambda^D_rdr)$, we calculate $\\mathbb{E}^\\mathbb{Q}_{t, x}[u^D(\\tau^D, X_{\\tau^D}) \\mathbb{1}_{\\tau^D < T} \\; | \\{ {X_{u}}\\}_{t \\leq u \\leq T}] = \\int_t^Tu^D(s,X_s)\\lambda^D_s exp(-\\int_t^s\\lambda^D_rdr)ds $, and so $\\mathbb{E}^\\mathbb{Q}_{t, x}[u^D(\\tau^D, X_{\\tau^D}) \\mathbb{1}_{\\tau^D < T}] = \\mathbb{E}^\\mathbb{Q}_{t, x}[\\int_t^Tu^D(s,X_s)\\lambda^D_s exp(-\\int_t^s\\lambda^D_rdr)ds] $\n",
    "\n",
    "Adding up the three terms results in:\n",
    "\\begin{equation}\n",
    "\\mathbb{E}^\\mathbb{Q}_{t, x} \\left[u^\\textrm{mat}(X_T) \\mathbb{1}_{\\tau^D \\geq T} -\\int_t^T\\alpha\\mathbb{1}_{\\tau^D>s}ds+ u^D(\\tau^D, X_{\\tau^D}) \\mathbb{1}_{\\tau^D < T} \\right] = \\\\ \\mathbb E_{t,x}^{\\mathbb{Q}} \\left[exp(-\\int_t^T\\lambda^D_sds) u_{mat}(X_T) + \\int_t^T exp(-\\int_t^s\\lambda_r^Ddr) \\cdot (\\lambda^D_su^D(s,X_s) - \\alpha)ds\\right]\n",
    "\\end{equation}\n",
    "\n",
    "as given by Feynman-Kac.\n",
    "\n",
    "We can perform Monte-Carlo simulations using this stochastic representation by setting $T$ (the upper limit of the integral) as some time $t_{k+1}$ and the time the pricing is done as time $t_{k}$. In this context, the option price at the present is priced in terms of the option price at the next time, which is an estimate of the future cash-flows presented to the option holder by owning the option. So for a given path, writing $u(t_k,t_k) = C^{p,t_k}_{t_k}$ as the price seen at time $t_{k}$ given no default events on or before $t_{k}$, we can rewrite our stochastic representation as: \n",
    "\n",
    "\\begin{equation}\n",
    "C^{p,t_k}_{t_k} = \\mathbb{E}_{t,x}^{\\mathbb{Q}} \\left[ exp(-\\int_t^{t_{k+1}}\\lambda^D_sds)C^{p,t_{k+1}}_{t_{k+1}}  + \\int_t^{t_{k+1}} exp(-\\int_t^s\\lambda_r^Ddr) \\cdot (\\lambda^D_su^D(s,X_s) - \\alpha)ds \\right]\n",
    "\\end{equation}\n",
    "\n",
    "and estimating/using the Euler-like scheme: $exp(-\\int_t^{t_{k+1}}\\lambda^D_sds) \\approx exp(-\\Delta t_{k+1}\\lambda^D_{t_{k+1}}) \\approx (1 - (\\Delta t_{k+1}\\lambda^D_{t_{k+1}}))$ and $exp(-\\int_t^s\\lambda_r^Ddr) \\approx exp(0) \\approx 1$ in the second integral, and $\\int_t^{t_{k+1}} (\\lambda^D_su^D(s,X_s) - \\alpha)ds \\approx  \\Delta t_{k+1}\\lambda^D_{t_{k+1}} u^D(t_{k+1}, X_{t_{k+1}}) - \\Delta t_{k+1}\\alpha$, we have:\n",
    "\n",
    "\\begin{equation}\n",
    "C^{p,t_k}_{t_k} = \\mathbb{E}_{t,x}^{\\mathbb{Q}} \\left[C^{p,t_{k+1}}_{t_{k+1}}(1 - (\\Delta t_{k+1}\\lambda^D_{t_{k+1}})) +\\Delta t_{k+1}\\lambda^D_{t_{k+1}} u^D(t_{k+1}, X_{t_{k+1}}) - \\Delta t_{k+1}\\alpha \\right]\n",
    "\\end{equation}\n",
    "\n",
    "and so for a given path of the underlying, and using the estimates $\\Delta t_{k+1}\\lambda^D_{t_{k+1}} \\approx 1 - exp(-\\Delta t_{k+1}\\lambda^D_{t_{k+1}})$ and $(1 - (\\Delta t_{k+1}\\lambda^D_{t_{k+1}})) \\approx exp(-\\Delta t_{k+1}\\lambda^D_{t_{k+1}})$, we have the scheme:\n",
    "\n",
    "\\begin{equation}\n",
    "C^{p,t_k}_{t_k} = C^{p,t_{k+1}}_{t_{k+1}}exp(-\\Delta t_{k+1}\\lambda^D_{t_{k+1}}) +(1 - exp(-\\Delta t_{k+1}\\lambda^D_{t_{k+1}})) u^D(t_{k+1}, X_{t_{k+1}}) - \\Delta t_{k+1}\\alpha \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9998585809554577"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating 100000 market paths\n",
    "S = 100\n",
    "vol = 0.3\n",
    "T = 10\n",
    "ts = np.linspace(0, T, int(np.round(T*12))+1)\n",
    "alpha = 3\n",
    "lambda_d = 0.025\n",
    "K_mat = 90.0\n",
    "K_D = 100.0\n",
    "\n",
    "npaths = 100000\n",
    "paths = blackscholes_mc(S=S, vol=vol, r=0, q=0, ts=ts, npaths=npaths)\n",
    "\n",
    "#create recursive function to calculate C recursively in terms of future values of C\n",
    "def recursive_C(t):\n",
    "    if (t == (len(ts) - 1)):\n",
    "        C = u_mat(paths[t])\n",
    "    else:\n",
    "        C = (recursive_C(t+1) * (1-p)) - (del_t*alpha) + (u_D(paths[t+1]) * p)\n",
    "    return C\n",
    "\n",
    "#calculate increment length, probability of death p, probability of no death (1-p)\n",
    "del_t = np.diff(ts)[0]\n",
    "p = 1 - np.exp(-(lambda_d * del_t))\n",
    "np.mean(recursive_C(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:darkorange\">Question 2</b> (Uncertain Mortality Rate Model - BSDE)\n",
    "\n",
    "Assume that $\\lambda^D_t \\in \\left[\\underline{\\lambda}^D, \\overline{\\lambda}^D \\right]$, where $\\underline{\\lambda}^D=0.005$ and $\\overline{\\lambda}^D=0.04$.\n",
    "\n",
    "<b>(a).</b> Implement the implicit Euler scheme for BSDE. Use piecewise-linear fit with 10 knots to estimate the conditional expectation $\\mathbb{E}^{\\mathbb{Q}}_{i-1}\\left[Y_{t_i}\\right]$. Use the numpy function percentile to define the minimum and maximum knots. Use the percentiles 1 and 99 percent. Use 100,000 paths.\n",
    "\n",
    "<b>(b).</b> Run an independent new simuation. Use the estimates of $\\mathbb{E}^{\\mathbb{Q}}_{i-1}\\left[Y_{t_i}\\right]$ obtained in (a) to get a lower bound estimate.\n",
    "\n",
    "<b>(c).</b> How does the price compare with the price in the model with deterministic mortality rate $\\underline{\\lambda}^D$? with deterministic mortality rate $\\overline{\\lambda}^D$? Check numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.408427365430355"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating 100000 market paths\n",
    "S = 100\n",
    "vol = 0.3\n",
    "T = 10\n",
    "ts = np.linspace(0, T, int(np.round(T*12))+1)\n",
    "alpha = 3\n",
    "lambda_min = 0.005\n",
    "lambda_max = 0.04\n",
    "K_mat = 90.0\n",
    "K_D = 100.0\n",
    "\n",
    "npaths = 50000\n",
    "paths = blackscholes_mc(S=S, vol=vol, r=0, q=0, ts=ts, npaths=npaths)\n",
    "\n",
    "#terminal value vector\n",
    "Y = u_mat(paths[-1])\n",
    "\n",
    "#matrix to store pw linear regression values\n",
    "vals = []\n",
    "\n",
    "for i in range(len(ts)-2, -1, -1):\n",
    "    del_t = ts[i+1] - ts[i]\n",
    "    #equally spaced knots based on the support points (current stock prices)\n",
    "    xknots = np.linspace(np.percentile(paths[i], 1), np.percentile(paths[i], 99), 10)\n",
    "    #calculate the weights for each basis function, vector B, using least squares minimization\n",
    "    #also returns the piecewise functions \n",
    "    ps, fs = pwlinear_fit(paths[i], Y, xknots)\n",
    "    #calculate the estimated conditional expected value of Y_{t+1} using time t Measurable values using\n",
    "    #pw linear regression\n",
    "    est = sum([f(paths[i])*p for (f, p) in zip(fs, ps)])\n",
    "    Y = np.where((u_D(paths[i]) >= (est - (alpha*del_t))), ((1 / ((lambda_max * del_t) + 1)) * (est -(alpha * del_t) + (u_D(paths[i]) * lambda_max * del_t))), ((1 / ((lambda_min * del_t) + 1)) * (est -(alpha * del_t) + (u_D(paths[i]) * lambda_min * del_t))))\n",
    "    \n",
    "    vals.append((fs,ps))\n",
    "np.mean(Y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.247535940442201"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating 100000 market paths\n",
    "S = 100\n",
    "vol = 0.3\n",
    "T = 10\n",
    "ts = np.linspace(0, T, int(np.round(T*12))+1)\n",
    "alpha = 3\n",
    "lambda_min = 0.005\n",
    "lambda_max = 0.04\n",
    "K_mat = 90.0\n",
    "K_D = 100.0\n",
    "\n",
    "npaths = 100000\n",
    "\n",
    "#generate paths for lower bound estimate\n",
    "paths = blackscholes_mc(S=S, vol=vol, r=0, q=0, ts=ts, npaths=npaths)\n",
    "\n",
    "#flip the stored estimates so it matches order of for loop\n",
    "vals = np.flip(vals, axis = 0)\n",
    "#terminal value vector\n",
    "Y = u_mat(paths[-1])\n",
    "\n",
    "#using old conditional expectation estimates to decide which lambda value to use, but using the new estimates\n",
    "#from this run to calculate the conditional expectation estimate in the actual equation\n",
    "for i in range(len(ts)-2, -1, -1):\n",
    "    del_t = ts[i+1] - ts[i]\n",
    "    #equally spaced knots based on the support points (current stock prices)\n",
    "    xknots = np.linspace(np.percentile(paths[i], 1), np.percentile(paths[i], 99), 10)\n",
    "    #calculate the weights for each basis function, vector B, using least squares minimization\n",
    "    #also returns the piecewise functions \n",
    "    ps, fs = pwlinear_fit(paths[i], Y, xknots)\n",
    "    #calculate the estimated conditional expected value of Y_{t+1} using time t Measurable values using\n",
    "    #pw linear regression\n",
    "    est = sum([f(paths[i])*p for (f, p) in zip(fs, ps)])\n",
    "    oldest = sum([f(paths[i])*p for (f, p) in zip(vals[i][0], vals[i][1])])\n",
    "    Y = np.where((u_D(paths[i]) >= (oldest - (alpha*del_t))), ((1 / ((lambda_max * del_t) + 1)) * (Y -(alpha * del_t) + (u_D(paths[i]) * lambda_max * del_t))), ((1 / ((lambda_min * del_t) + 1)) * (Y -(alpha * del_t) + (u_D(paths[i]) * lambda_min * del_t))))\n",
    "\n",
    "\n",
    "np.mean(Y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Constant Deterministic Lambda of 0.04 gives a price of 3.1452392341206457\n",
      "Using Constant Deterministic Lambda of 0.005 gives a price of 0.3703958239837211\n"
     ]
    }
   ],
   "source": [
    "#generating 100000 market paths\n",
    "npaths = 100000\n",
    "paths = blackscholes_mc(S=S, vol=vol, r=0, q=0, ts=ts, npaths=npaths)\n",
    "\n",
    "#calculating price using deterministic max\n",
    "lambda_d = 0.04\n",
    "p = 1 - np.exp(-(lambda_d * del_t))\n",
    "max_val = np.mean(recursive_C(0))\n",
    "\n",
    "#calculating price using deterministic min\n",
    "lambda_d = 0.005\n",
    "p = 1 - np.exp(-(lambda_d * del_t))\n",
    "min_val = np.mean(recursive_C(0))\n",
    "\n",
    "print(\"Using Constant Deterministic Lambda of 0.04 gives a price of {}\".format(max_val))\n",
    "print(\"Using Constant Deterministic Lambda of 0.005 gives a price of {}\".format(min_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown when using the lower bound estimate from BSDEs, the reinsurance deal price is around 3.2 USD. This is in contrast to using the deterministic lambda upper bound of 0.04, which returns a value of around 3.10 USD and to using the deterministic lambda lower bound of 0.005, which returns a value of around 0.35 USD.\n",
    "\n",
    "These results make sense make sense in the context of using the HJB PDE since the uncertain death rate model ensures the supremum over all possible prices is 'selected' at a given time, and thus the reinsurance deal seller is most likely to be hedged (conditional on the path of the underlying) by using the higher price resulting from the HJB PDE. So the price from the BSDE analog to the HJB PDE is higher than both prices using the deterministic lambdas. When using the deterministic lower bound rate as a constant, the death rate appears to be very low and thus the product is priced accordingly, which basically like a 10-year European put with a constant fee, thus making the value relatively low. When using the deterministic upper bound rate the price is close to the HJB PDE price, since the higher death rate implies that in cases where the value $u^D$ was higher than $u$, death was more likely and thus the reinsurance deal buyer had more benefit, and thus the price of the deal was high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:darkorange\">Question 3</b> (Uncertain Mortality Rate Model - Longstaff and Schwartz) In addition to the BSDE simulation, the reinsurance deals can be priced by adapting the Longstaff-Schwartz algorithm. An implementation of the Longstaff-Schwartz algorithm is provided below for your convenience.\n",
    "\n",
    "The same lower and upper bounds of $\\lambda_t^D$ are used as Question 2.\n",
    "\n",
    "<b>(a).</b> In the example code, we use European put price (the strike is taken to be the average of $K_{\\text{mat}}$ and $K_D$) and constant as basis functions to estimate the sum of future payoffs. Modify the code by using the piecewise-linear fit to estimate the sum of future payoffs.\n",
    "\n",
    "<b>(b).</b> Compare the BSDE scheme with the Longstaff-Schwartz-like scheme in terms of variance. For each method run the two-step procedure (regression and indedenpent pricing) 20 times to estimate variance. Use 5000 paths for regression and 50000 for indepedent pricing.\n",
    "\n",
    "<b>(c).</b> What is approximately the value of the fee $\\alpha$ that makes the deal costless at inception?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.210311780987608"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Longstaff-Schwartz algorithm for Uncertain Mortality Rate Model\n",
    "S = 100\n",
    "vol = 0.3\n",
    "T = 10\n",
    "ts = np.linspace(0, T, int(np.round(T*12))+1)\n",
    "alpha = 3\n",
    "lambda_min = 0.005\n",
    "lambda_max = 0.04\n",
    "\n",
    "K_mat = 90.0\n",
    "K_D = 100.0\n",
    "\n",
    "#I put my changes in the example code. Basically I just replace the sections relating to regression\n",
    "# first Monte Carlo run to estimate the value function by regressions\n",
    "npaths = 5000\n",
    "paths = blackscholes_mc(S=S, vol=vol, r=0, q=0, ts=ts, npaths=npaths)\n",
    "vals = []\n",
    "V = u_mat(paths[-1])\n",
    "lambd = np.where(u_D(paths[-1]) >= V, lambda_max, lambda_min)\n",
    "K = 0.5*(K_mat+K_D)\n",
    "for i in range(len(ts)-2, -1, -1):\n",
    "    dt = ts[i+1]-ts[i]\n",
    "    p = 1-np.exp(-lambd*dt)\n",
    "    V = p*u_D(paths[i+1]) + (1-p)*V - alpha*dt\n",
    "    #equally spaced knots based on the support points (current stock prices)\n",
    "    xknots = np.linspace(np.percentile(paths[i], 1), np.percentile(paths[i], 99), 10)\n",
    "    #calculate the weights for each basis function, vector B, using least squares minimization\n",
    "    #also returns the piecewise functions \n",
    "    ps, fs = pwlinear_fit(paths[i], V, xknots)\n",
    "    #calculate the estimated conditional expected value of Y_{t+1} using time t Measurable values using\n",
    "    #pw linear regression\n",
    "    est = sum([f(paths[i])*p for (f, p) in zip(fs, ps)])\n",
    "    vals.append((fs,ps))\n",
    "    lambd = np.where(u_D(paths[i]) >= est, lambda_max, lambda_min)\n",
    "   \n",
    "vals = np.flip(vals, axis = 0)\n",
    "\n",
    "# independent simulation to obtain a lower bound\n",
    "npaths = 100000\n",
    "paths = blackscholes_mc(S=S, vol=vol, r=0, q=0, ts=ts, npaths=npaths)\n",
    "V = u_mat(paths[-1])\n",
    "lambd = np.where(u_D(paths[-1]) >= V, lambda_max, lambda_min)\n",
    "for i in range(len(ts)-2, -1, -1):\n",
    "    dt = ts[i+1]-ts[i]\n",
    "    p = 1-np.exp(-lambd*dt)\n",
    "    V = p*u_D(paths[i+1]) + (1-p)*V - alpha*dt\n",
    "    est = sum([f(paths[i])*p for (f, p) in zip(vals[i][0], vals[i][1])])\n",
    "    lambd = np.where(u_D(paths[i]) >= est, lambda_max, lambda_min)\n",
    "np.mean(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating functions to perform the BSDE and LS-like algorithms\n",
    "def BSDEfcn(alpha):\n",
    "    npaths = 5000\n",
    "    paths = blackscholes_mc(S=S, vol=vol, r=0, q=0, ts=ts, npaths=npaths)\n",
    "    Y = u_mat(paths[-1])\n",
    "    vals = []\n",
    "    for i in range(len(ts)-2, -1, -1):\n",
    "        del_t = ts[i+1] - ts[i]\n",
    "        xknots = np.linspace(np.percentile(paths[i], 1), np.percentile(paths[i], 99), 10)\n",
    "        ps, fs = pwlinear_fit(paths[i], Y, xknots)\n",
    "        est = sum([f(paths[i])*p for (f, p) in zip(fs, ps)])\n",
    "        Y = np.where((u_D(paths[i]) >= (est - (alpha*del_t))), ((1 / ((lambda_max * del_t) + 1)) * (est -(alpha * del_t) + (u_D(paths[i]) * lambda_max * del_t))), ((1 / ((lambda_min * del_t) + 1)) * (est -(alpha * del_t) + (u_D(paths[i]) * lambda_min * del_t))))\n",
    "        vals.append((fs,ps))\n",
    "    npaths = 50000\n",
    "    paths = blackscholes_mc(S=S, vol=vol, r=0, q=0, ts=ts, npaths=npaths)\n",
    "    vals = np.flip(vals, axis = 0)\n",
    "    Y = u_mat(paths[-1])\n",
    "    for i in range(len(ts)-2, -1, -1):\n",
    "        del_t = ts[i+1] - ts[i]\n",
    "        oldest = sum([f(paths[i])*p for (f, p) in zip(vals[i][0], vals[i][1])])\n",
    "        Y = np.where((u_D(paths[i]) >= (oldest - (alpha*del_t))), ((1 / ((lambda_max * del_t) + 1)) * (Y -(alpha * del_t) + (u_D(paths[i]) * lambda_max * del_t))), ((1 / ((lambda_min * del_t) + 1)) * (Y -(alpha * del_t) + (u_D(paths[i]) * lambda_min * del_t))))\n",
    "    return np.mean(Y)  \n",
    "\n",
    "def LSLfcn(alpha):\n",
    "    npaths = 5000\n",
    "    paths = blackscholes_mc(S=S, vol=vol, r=0, q=0, ts=ts, npaths=npaths)\n",
    "    vals = []\n",
    "    V = u_mat(paths[-1])\n",
    "    lambd = np.where(u_D(paths[-1]) >= V, lambda_max, lambda_min)\n",
    "    K = 0.5*(K_mat+K_D)\n",
    "    for i in range(len(ts)-2, -1, -1):\n",
    "        dt = ts[i+1]-ts[i]\n",
    "        p = 1-np.exp(-lambd*dt)\n",
    "        V = p*u_D(paths[i+1]) + (1-p)*V - alpha*dt\n",
    "        xknots = np.linspace(np.percentile(paths[i], 1), np.percentile(paths[i], 99), 10)\n",
    "        ps, fs = pwlinear_fit(paths[i], V, xknots)\n",
    "        est = sum([f(paths[i])*p for (f, p) in zip(fs, ps)])\n",
    "        vals.append((fs,ps))\n",
    "        lambd = np.where(u_D(paths[i]) >= est, lambda_max, lambda_min)\n",
    "        \n",
    "    vals = np.flip(vals, axis = 0)\n",
    "    npaths = 50000\n",
    "    paths = blackscholes_mc(S=S, vol=vol, r=0, q=0, ts=ts, npaths=npaths)\n",
    "    V = u_mat(paths[-1])\n",
    "    lambd = np.where(u_D(paths[-1]) >= V, lambda_max, lambda_min)\n",
    "    for i in range(len(ts)-2, -1, -1):\n",
    "        dt = ts[i+1]-ts[i]\n",
    "        p = 1-np.exp(-lambd*dt)\n",
    "        V = p*u_D(paths[i+1]) + (1-p)*V - alpha*dt\n",
    "        est = sum([f(paths[i])*p for (f, p) in zip(vals[i][0], vals[i][1])])\n",
    "        lambd = np.where(u_D(paths[i]) >= est, lambda_max, lambda_min)\n",
    "    return np.mean(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbiased Sample Variance Estimate for BSDEs = 0.015262832983332432\n",
      "Unbiased Sample Variance Estimate for LS-L algorithm = 0.009759824725293312\n",
      "Average of BSDEs = 3.188363862021121\n",
      "Average of LS-L algorithm = 3.2352499259719414\n"
     ]
    }
   ],
   "source": [
    "S = 100\n",
    "vol = 0.3\n",
    "T = 10\n",
    "ts = np.linspace(0, T, int(np.round(T*12))+1)\n",
    "alpha = 3\n",
    "lambda_min = 0.005\n",
    "lambda_max = 0.04\n",
    "\n",
    "K_mat = 90.0\n",
    "K_D = 100.0\n",
    "\n",
    "#calculating the results of 20 runs\n",
    "BSDEresults = [BSDEfcn(3.0) for i in range(0,20,1)]\n",
    "LSLresults = [LSLfcn(3.0) for i in range(0,20,1)]\n",
    "\n",
    "#outputting variance and mean\n",
    "print(\"Unbiased Sample Variance Estimate for BSDEs = {}\".format(np.var(BSDEresults, ddof=1)))\n",
    "print(\"Unbiased Sample Variance Estimate for LS-L algorithm = {}\".format(np.var(LSLresults, ddof=1)))\n",
    "print(\"Average of BSDEs = {}\".format(np.mean(BSDEresults)))\n",
    "print(\"Average of LS-L algorithm = {}\".format(np.mean(LSLresults)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample variance (using Bessel's correction) was 0.0104 for the BSDE low biased prices and 0.006 for the LS-L algorithm low biased prices. The average price using the BSDE low biased prices was around 3.2 USD and the average price using the LS-L algorithm was around 3.25 USD. \n",
    "\n",
    "The price using the LS-L algorithm was higher than in 3a where I used 100000 runs for the independent pricing, which always seemed to result in a value closer to 3.2 USD, but using the lower amount of runs may account for this. I think a slightly higher price using the LS-L algorithm makes sense since the algorithm incorporates information directly from the 'future' on the first backward step of the pricing, as it calculates lambda for time $t_{t_{n-1}}$ using the actual time $t_{t_n}$ payoff and then calculates the price to be used for the price calculation at time $t_{t_{n-2}}$ using these actual future values (although after this first backward step, the lambda is now estimated). So in the context here, whenever the time $t_{t_n}$ payoff is such that $u^D$ is higher, the lambda value used at $t_{t_{n-1}}$ is the max lambda, while whenever the time $t_{t_n}$ payoff is such that $u$ is higher, the minimum lambda is used. So this is analogous to the Longstaff-Schwartz American pricing where the exercise decision (here it is using lambda max or lambda min) looks into the future and then makes a decision on pricing using that future information directly. \n",
    "\n",
    "The BSDE prices and LS-L prices had similar variance, usually with the BSDE pricing having slightly higher (but still not very big in the context of the generally low numbers here). This is likely due to the fact that the BSDE pricing is similar to TVR pricing of American options, where the estimate of the future value is calculated as each time and used for the next step's calculation and so on, thus carrying over any errors through the time steps. In contrast, the LS-L algorithm only selects a lambda value at a time $t_{k}$ and uses that lambda value in order to calculate the likelihood of death when estimating the future cashflows (so averaging over default events) at time $t_{k-1}$. This is like in the LS algorithm for American options where the regression estimates of the future value of the option isn't used, rather just the optimal time of future cash flows is estimated and the cash flows left the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSLfcnx20(alpha):\n",
    "    return np.mean([LSLfcn(alpha) for i in range(0,20,1)])\n",
    "def BSDEfcnx20(alpha):\n",
    "    return np.mean([BSDEfcn(alpha) for i in range(0,20,1)])\n",
    "\n",
    "#fair_fee_LSL = scipy.optimize.brentq(LSLfcnx20, 3.379,3.389)\n",
    "#scipy.optimize.brentq(BSDEfcnx20, 3.35,3.4)\n",
    "\n",
    "#print(\"The approximate fair fee per year, alpha, using the LSL algorithm is {} USD\".format(fair_fee_LSL))\n",
    "#print(\"The price using {} as the fee is approximately (using 20 runs) {} USD\".format(fair_fee_LSL, LSLfcnx20(fair_fee_LSL)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.037527922110316046"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hardcoded calculation of LS-L price given LS-L fair fee\n",
    "LSLfcnx20(3.385)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fair fee is such that $u(t,x,\\alpha) = 0$ at the time pricing is performed. Therefore a root-finding method is needed to calculate alpha such that the price returns 0. I did this using one of scipy's root finding functions, and performed it on both the LS-L and BSDE pricing functions. The issue with root finding here is that the functions are random and have variance (especially the BSDE pricing) and so finding a root takes a fair amount of time and doesn't return a value of exactly $0$. The root finding was done using the average of 20 runs at each alpha value in order to get a better approximation over multiple possible paths of the underlying. In the code, I commented out the LS-L and BSDE pricing root finding since those lines' execution takes an inordinate amount of time. \n",
    "\n",
    "The BSDE function returned a fair fee of $3.38$ USD and the LS-L function returned a fair fee of also around $3.385$ USD, depending on the run. The price returned by the functions using the fair fee wasn't exactly $0$ on any one run, and could be negative depending on the run if the fee was a bit too high, but was typically very close. I opted to use the results from the LS-L function and root finding since there was less variance in the result, and so I'd be more confident as a reinsurance deal seller to quote that value as the fair fee. The price over 20 runs using the LS-L algorithm and the fair fee of $3.385$ USD returned a price of $0.01$ USD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b style=\"color:darkorange\">Question 4.</b> Set $K_D=0$, and all the other parameters remain the smae, in particualr $\\alpha=3$. Then the default event is equivalent to lapse (with no mortality payoff). It has been observed that insurance subscribers do not lapse optimally, which explains the use of the uncertain lapse model with minimum and maximum lapse rates $\\underline{\\lambda}$, $\\overline{\\lambda}$. \n",
    "\n",
    "<b>(a).</b> If insurance subscribers were to lapse optimally, i.e., exercise optimally their option to lapse, how would you price the contract?\n",
    "\n",
    "<b>(b).</b> Explain how you can get this price (from optimal exercise) in the uncertain lapse model. Reuse the code provided in Question 3 to show your result (you may have to change some parameters in the code).\n",
    "\n",
    "<b>(c).</b> Implement Longstaff-Schwartz algorithm to price the American option with payoff $u^D=0$ (Always perform a second indepedent run to get a clean lower bound price). Compare the price from uncertain lapse model in part (b) with the American price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Insurance subscribers were to lapse optimally, they'd lapse immediately as soon as $u^D$ (normally $u^L$) was such that $u^D > u$. This condition implies that lapsing is more valuable a choice for the subscriber than to continue on with the insurance, and we can write this mathematically using the condition that when performing pricing, $u^D \\leq u$, implying $u^D - u \\leq 0$, and while this is true, that no lapsing occurs, thus $\\lambda^D_s = 0$, and so the HJB PDE turns into, whenever it is not optimal to exercise: \n",
    "\\begin{equation}\n",
    "\\left\\{\\begin{array}{l}\\partial_t u + \\frac{1}{2}\\sigma^2 x^2 \\partial_x^2 u - \\alpha = 0\\\\\n",
    "        u(T, x) \\equiv u^\\textrm{mat}(x)\\end{array}\\right.\n",
    "\\end{equation}\n",
    "and so combining the two conditions we arrive at the variational inequality: $max\\left\\{\\partial_t u + \\frac{1}{2}\\sigma^2 x^2 \\partial_x^2 u - \\alpha, u^D - u\\right\\} = 0$, which can be solved to calculate the value of the option, similar to the solving of the variational inequality during American option pricing. Typically, the lapsing value is $0$, and so we'd use $u^D = 0$ to include this as the payoff during the pricing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Question 4 b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the optimal lapse value of the option is such that subscribers only lapse on the condition that $u^D > u$, then we can price the option using the Longstaff Schwartz like algorithm, by making it such that whenever $u^D > u$, that lapse occurs. In the context of the Poisson process, making the arrival occur with probability 1 is equivalent to having an infinite parameter, and so we can set $\\bar{\\lambda}^D= \\infty$, to 'force' lapsing. Equivalently whenever the condition $u^D > u$ is not fulfilled, we want to ensure no lapse occurs, and this is equivalent to setting $\\underline{\\lambda}^D= 0$. (Note that the code in Question 3, uses the condition $u^D \\geq u$, but this does not affect the pricing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6667929255332066"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = 100\n",
    "vol = 0.3\n",
    "T = 10\n",
    "ts = np.linspace(0, T, int(np.round(T*12))+1)\n",
    "alpha = 3\n",
    "lambda_min = 0\n",
    "lambda_max = math.inf\n",
    "\n",
    "K_mat = 90.0\n",
    "K_D = 0\n",
    "\n",
    "LSLfcn(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.55879698461972"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#longstaff schwartz algorithm for American pricing\n",
    "npaths = 5000\n",
    "S = 100\n",
    "vol = 0.3\n",
    "T = 10\n",
    "ts = np.linspace(0, T, int(np.round(T*12))+1)\n",
    "alpha = 3\n",
    "paths = blackscholes_mc(S=100.0, vol=0.3, r=0, q=0, ts=ts, npaths=npaths)\n",
    "del_t = np.diff(ts)[0]\n",
    "\n",
    "K_mat = 90.0\n",
    "\n",
    "#create array that holds coefficients from LS\n",
    "vals = []\n",
    "\n",
    "payoff = u_mat(paths[-1])\n",
    "for i in range(len(ts)-2, -1, -1):\n",
    "    payoff = payoff - (alpha*del_t)\n",
    "    xknots = np.linspace(np.percentile(paths[i], 1), np.percentile(paths[i], 99), 10)\n",
    "    ps, fs = pwlinear_fit(paths[i], payoff, xknots)\n",
    "    if i == (len(ts)-2):\n",
    "        contval = payoff\n",
    "    else:\n",
    "        contval = sum([f(paths[i])*p for (f, p) in zip(fs, ps)]) \n",
    "    exerval = (np.ones_like(paths[1,:], dtype=np.float) * 0.0) - (alpha * del_t)\n",
    "    ind = exerval >= contval\n",
    "    payoff[ind] = exerval[ind]\n",
    "    vals.append((fs,ps))\n",
    "\n",
    "vals = np.flip(vals, axis = 0)    \n",
    "    \n",
    "# independent simulation to obtain a lower bound\n",
    "npaths = 100000\n",
    "paths = blackscholes_mc(S=S, vol=vol, r=0, q=0, ts=ts, npaths=npaths)\n",
    "payoff = u_mat(paths[-1])\n",
    "for i in range(len(ts)-2, -1, -1):\n",
    "    payoff = payoff - (alpha*del_t)\n",
    "    if i == (len(ts)-2):\n",
    "        contval = payoff\n",
    "    else:\n",
    "        contval = sum([f(paths[i])*p for (f, p) in zip(vals[i][0], vals[i][1])])\n",
    "    exerval = (np.ones_like(paths[1,:], dtype=np.float) * 0.0) - (alpha * del_t)\n",
    "    ind = exerval >= contval\n",
    "    payoff[ind] = exerval[ind]\n",
    "\n",
    "np.mean(payoff)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When performing the pricing of the deal as if it were an American option, when using 5000 initial and 100000 subsequent runs for the low biased pricing, the price was around $3.6$ USD, as compared to the Longstaff-Schwartz like algorithm giving a price of around $3.65$ USD when using a comparable number of runs in the simulation. \n",
    "\n",
    "A few adjustments had to be made to the Longstaff Schwartz algorithm for American options (LSA) to price the reinsurance deal properly. For example the payoff of exercising at all times had to become $0$, indicative of the lapse value, and also since the reinsurance deal Longstaff Schwartz-like algorithm made the assumption of no exercise/lapse occurring on the current date, the exercise value in the LSA algorithm had to be $0$ less the monthly fee. Since there was now a fee involved, the LSA algorithm also had to be modified so that the payoff was decreased by the monthly fee each time step. \n",
    "\n",
    "The main difference between the two algorithms, was that the LS-like algorithm for reinsurance deals calculates the value on the date $t_{n-1}$ using the information directly from the date $t_n$ information, and in general, estimating lambda for the previous time using regression on the value calculated at the present time. On the other hand, the LSA algorithm doesn't have the 'looking into the future' issue and always estimates future payoffs using the regression, and performs the lapse/exercise decision using regression. This results in a slightly higher price using the LS-like algorithm. I tried letting the LSA algorithm look into the future at time $t_{n-1}$ as well, by letting the continuation value equal the actual future payoff, and this resulted in even more similar prices between the two algorithms."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": "Uncertain Mortality.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
